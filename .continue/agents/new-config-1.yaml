# This is an example configuration file
# To learn more, see the full config.yaml reference: https://docs.continue.dev/reference

name: Local Machine
version: 1.0.0
schema: v1
models:
  - name: LMStudio Chat
    provider: lmstudio
    model: AUTODETECT
    apiBase: http://localhost:1234/v1/
    roles:
      - apply
      - autocomplete
      - chat
      - edit
  - name: qwen2.5-7b-rx2080-host
    provider: lmstudio
    model: qwen2.5-coder-7b-instruct
    apiBase: http://192.168.100.55:1234/v1/
    roles:
      - autocomplete
  - uses: openai/gpt-4.1
    with:
      OPENAI_API_KEY: xxx
  - uses: openai/o3
    with:
      OPENAI_API_KEY: xxx
  - uses: openai/gpt-4.1-mini
    with:
      OPENAI_API_KEY: xxx
chat:
  model: LMStudio Chat
context:
  - provider: code
  - provider: docs
  - provider: diff
  - provider: terminal
  - provider: problems
  - provider: folder
  - provider: codebase